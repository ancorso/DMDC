diff --git a/pyfr/plugins/controller.py b/pyfr/plugins/controller.py
new file mode 100644
index 0000000..9a21076
--- /dev/null
+++ b/pyfr/plugins/controller.py
@@ -0,0 +1,391 @@
+# -*- coding: utf-8 -*-
+import glob
+import h5py
+import json
+import numpy as np
+import os, sys
+import subprocess
+# import tensorflow as tf
+import argparse
+import random
+
+from cvxpy import *
+from builtins import min
+from builtins import max
+# from koopman_model import KoopmanModel
+from pyfr.mpiutil import get_comm_rank_root, get_mpi
+from pyfr.plugins.base import BasePlugin
+
+
+def _closest_upts_bf(etypes, eupts, pts):
+    for p in pts:
+        # Compute the distances between each point and p
+        dists = [np.linalg.norm(e - p, axis=2) for e in eupts]
+
+        # Get the index of the closest point to p for each element type
+        amins = [np.unravel_index(np.argmin(d), d.shape) for d in dists]
+
+        # Dereference to get the actual distances and locations
+        dmins = [d[a] for d, a in zip(dists, amins)]
+        plocs = [e[a] for e, a in zip(eupts, amins)]
+
+        # Find the minimum across all element types
+        yield min(zip(dmins, plocs, etypes, amins))
+
+
+def _closest_upts_kd(etypes, eupts, pts):
+    from scipy.spatial import cKDTree
+
+    # Flatten the physical location arrays
+    feupts = [e.reshape(-1, e.shape[-1]) for e in eupts]
+
+    # For each element type construct a KD-tree of the upt locations
+    trees = [cKDTree(f) for f in feupts]
+
+    for p in pts:
+        # Query the distance/index of the closest upt to p
+        dmins, amins = zip(*[t.query(p) for t in trees])
+
+        # Unravel the indices
+        amins = [np.unravel_index(i, e.shape[:2])
+                 for i, e in zip(amins, eupts)]
+
+        # Dereference to obtain the precise locations
+        plocs = [e[a] for e, a in zip(eupts, amins)]
+
+        # Reduce across element types
+        yield min(zip(dmins, plocs, etypes, amins))
+
+
+def _closest_upts(etypes, eupts, pts):
+    try:
+        # Attempt to use a KD-tree based approach
+        yield from _closest_upts_kd(etypes, eupts, pts)
+    except ImportError:
+        # Otherwise fall back to brute force
+        yield from _closest_upts_bf(etypes, eupts, pts)
+
+class FillerArgs:
+    code_dim = -1
+    action_dim = -1
+
+
+class ControllerPlugin(BasePlugin):
+    name = 'controller'
+    systems = ['*']
+    formulations = ['dual', 'std']
+
+    def __init__(self, intg, cfgsect, suffix):
+        super().__init__(intg, cfgsect, suffix)
+
+        # Underlying elements class
+        self.elementscls = intg.system.elementscls
+
+        # Process frequency and other params
+        self.nsteps = self.cfg.getint(cfgsect, 'nsteps')
+        self.save_data = self.cfg.getint(cfgsect, 'savedata')
+        self.set_omega = self.cfg.getint(cfgsect, 'setomega')
+        self.perform_offline_dmdc = (self.cfg.getint(cfgsect, 'offline_dmdc') == 1)
+        self.perform_online_dmdc = (self.cfg.getint(cfgsect, 'online_dmdc') == 1)
+        self.mpc_prediction_window = self.cfg.getint(cfgsect, 'mpc_prediction_window')
+        self.iteration = 0
+
+        # List of points to be sampled and format
+        self.pts = self.cfg.getliteral(cfgsect, 'samp-pts')
+        self.fmt = self.cfg.get(cfgsect, 'format', 'primitive')
+
+        # Define directory where solution snapshots should be saved
+        self.save_dir = self.cfg.getpath(cfgsect, 'save_dir')
+
+        # If performing dmdc, load matrices
+        if self.perform_offline_dmdc:
+            # Set constraints for mpc
+            self.R = self.cfg.getfloat(cfgsect, 'R')
+            self.u_max = self.cfg.getfloat(cfgsect, 'u_max')
+
+            # Load desired attributes from file
+            f = h5py.File('./A_B_Uhat.h5', 'r')
+            self.A = np.array(f['A']).T
+            self.B = np.array(f['B']).T
+            self.U_hat_t = np.array(f['U_hat'])
+            if self.U_hat_t.shape[0] != self.A.shape[1]:
+                self.U_hat_t = self.U_hat_t.T
+            self.args = FillerArgs()
+            self.args.code_dim = np.size(self.U_hat_t, 0)
+            self.args.action_dim = np.size(self.B, 1)
+
+            print("Size A: ", self.A.shape, " Size B: ", self.B.shape, " Size U_hat: ", self.U_hat_t.shape)
+
+            f = h5py.File(self.cfg.getpath(cfgsect, 'base_flow'), 'r')
+            self.goal_state = self.U_hat_t @ np.array(f['sol_data']).flatten()
+
+        if self.perform_online_dmdc:
+            # set sequence length and get path to julia code for computing dmdc
+            self.dmdc_seq_len = self.cfg.getint(cfgsect, 'dmdc_seq_len')
+            self.dmdc_train_path = self.cfg.getpath(cfgsect, 'dmdc_train_path')
+            self.dmdc_recompute_duration = self.cfg.getint(cfgsect, 'dmdc_recompute_duration')
+            sys.path.append(self.dmdc_train_path)
+
+            # Store untransformed base flow data
+            f = h5py.File(self.cfg.getpath(cfgsect, 'base_flow'), 'r')
+            self.raw_goal_state = np.array(f['sol_data']).flatten()
+
+            # Set constraints for mpc
+            self.R = self.cfg.getfloat(cfgsect, 'R')
+            self.u_max = self.cfg.getfloat(cfgsect, 'u_max')
+
+            # Load starting dynamics
+            f = h5py.File('./A_B_Uhat.h5', 'r')
+            self.A = np.array(f['A']).T
+            self.B = np.array(f['B']).T
+            self.U_hat_t = np.array(f['U_hat'])
+            if self.U_hat_t.shape[0] != self.A.shape[1]:
+                self.U_hat_t = self.U_hat_t.T
+            self.args = FillerArgs()
+            self.args.code_dim = np.size(self.U_hat_t, 0)
+            self.args.action_dim = np.size(self.B, 1)
+
+            print("Size A: ", self.A.shape, " Size B: ", self.B.shape, " Size U_hat: ", self.U_hat_t.shape)
+
+            # Define array to hold old time snapshots and control inputs of the system
+            self.X = np.zeros((self.dmdc_seq_len + 1, 128, 256, 4), dtype=np.float32)
+            self.u = np.zeros((self.dmdc_seq_len, self.args.action_dim), dtype=np.float32)
+
+            print("Constructed X", self.X.shape, "and u", self.u.shape, "history vectors")
+
+        # Initial omega
+        intg.system.omega = 0
+
+        # MPI info
+        comm, rank, root = get_comm_rank_root()
+
+        # MPI rank responsible for each point and rank-indexed info
+        self._ptsrank = ptsrank = []
+        self._ptsinfo = ptsinfo = [[] for i in range(comm.size)]
+
+        # Physical location of the solution points
+        plocs = [p.swapaxes(1, 2) for p in intg.system.ele_ploc_upts]
+
+        # Load map from point to index
+        with open('loc_to_idx.json') as loc_to_idx:
+            loc_to_idx_str = json.load(loc_to_idx,)
+            self.loc_to_idx = dict()
+            for key in loc_to_idx_str:
+                self.loc_to_idx[int(key)] = loc_to_idx_str[key]
+
+
+        # Locate the closest solution points in our partition
+        closest = _closest_upts(intg.system.ele_types, plocs, self.pts)
+
+        # Process these points
+        for cp in closest:
+            # Reduce over the distance
+            _, mrank = comm.allreduce((cp[0], rank), op=get_mpi('minloc'))
+
+            # Store the rank responsible along with its info
+            ptsrank.append(mrank)
+            ptsinfo[mrank].append(
+                comm.bcast(cp[1:] if rank == mrank else None, root=mrank)
+            )
+
+    def _process_samples(self, samps):
+        samps = np.array(samps)
+
+        # If necessary then convert to primitive form
+        if self.fmt == 'primitive' and samps.size:
+            samps = self.elementscls.con_to_pri(samps.T, self.cfg)
+            samps = np.array(samps).T
+
+        return samps.tolist()
+
+    # Find A-matrix and initial code value from neural network
+    def _find_dmdc_dynamics(self):
+        print("Finding DMDc dynamics...")
+
+        # Save X and u to file
+        #f = h5py.File('./X_u.h5', 'w')
+        #f['X'] = self.X
+        #f['u'] = self.u
+        #f.close()
+        dstart = self.iteration - self.dmdc_seq_len
+        dend = self.iteration-2
+        print("Start iteration: ", dstart, " end iteration: ", dend)
+
+        # Run python script to find A matrix and initial state
+        command = "julia " + self.dmdc_train_path + "compute_dmdc_dynamics.jl files " + self.save_dir + "/ " + str(dstart) + " " + str(dend)
+        subprocess.call(command.split())
+
+        # Load desired values from file and return
+        f = h5py.File('A_B_Uhat.h5', 'r')
+        self.A = np.array(f['A']).T
+        self.B = np.array(f['B']).T
+        self.U_hat_t = np.array(f['U_hat'])
+        if self.U_hat_t.shape[0] != self.A.shape[1]:
+            self.U_hat_t = self.U_hat_t.T
+        self.args.code_dim = np.size(self.U_hat_t, 0)
+        self.args.action_dim = np.size(self.B, 1)
+        print("done")
+
+
+    # Perform MPC optimization to find next input
+    # Following example from CVXPY documentation
+    def _find_mpc_input(self, A, B, x0):
+        print('\nRunning MPC to get optimal omega from dmdc dynamics...')
+        # First define prediction horizon
+        T = self.mpc_prediction_window
+
+        # Define variables
+        x = Variable(shape = (self.args.code_dim, T+1))
+        u = Variable(shape = (self.args.action_dim, T))
+
+        # Define costs for states and inputs
+        Q = np.eye(self.args.code_dim)
+        R = self.R*np.eye(self.args.action_dim)
+
+        # Construct and solve optimization problem
+        cost = 0
+        constr = []
+        for t in range(T):
+            cost += quad_form((self.goal_state - x[:,t]), Q) + quad_form(u[:,t], R)
+            constr += [x[:,t+1] == A*x[:,t] + B*u[:,t],
+                        norm(u[:,t], 'inf') <= self.u_max]
+
+        # Sum problem objectives and concatenate constraints
+        constr += [x[:,0] == x0]
+        prob = Problem(Minimize(cost),constr)
+        prob.solve()
+
+        # x1 = np.array([x.value[i, 1] for i in range(x.value.shape[0])])
+        try:
+            print('Optimal Omega: ', u.value[0, 0])
+            return u.value[0, 0] # Change if not scalar input
+        except:
+            print("Error: u was not a scalar")
+            return 0.0
+
+    def __call__(self, intg):
+        # Return if there is nothing to do for this step
+        if (intg.nacptsteps % self.nsteps):
+            return
+
+        # MPI info
+        comm, rank, root = get_comm_rank_root()
+
+        # Solution matrices indexed by element type
+        solns = dict(zip(intg.system.ele_types, intg.soln))
+
+        # Points we're responsible for sampling
+        ourpts = self._ptsinfo[comm.rank]
+
+        # Sample the solution matrices at these points
+        samples = [solns[et][ui, :, ei] for _, et, (ui, ei) in ourpts]
+        samples = self._process_samples(samples)
+
+        # Gather to the root rank to give a list of points per rank
+        samples = comm.gather(samples, root=root)
+
+        # If we're the root rank process the data
+        if rank == root:
+            data = []
+
+            # Collate
+            iters = [zip(pi, sp) for pi, sp in zip(self._ptsinfo, samples)]
+
+            for mrank in self._ptsrank:
+                # Unpack
+                (ploc, etype, idx), samp = next(iters[mrank])
+
+                # Determine the physical mesh rank
+                prank = intg.rallocs.mprankmap[mrank]
+
+                # Prepare the output row [[x, y], [rho, rhou, rhouv, E]]
+                row = [ploc, samp]
+
+                # Append
+                data.append(row)
+
+            # Define info for saving to file
+            list_of_files = glob.glob(self.save_dir + '/*')
+            if len(list_of_files) == 0:
+                file_num = 0
+            else:
+                latest_file = max(list_of_files, key=os.path.getctime)
+                file_num = int(latest_file[-7:-3])
+
+            # Save data in desired format
+            # Define freestream values for to be used for cylinder
+            rho = 1.0
+            P = 1.0
+            u = 0.236
+            v = 0.0
+            e = P/rho/0.4 + 0.5*(u**2 + v**2)
+            freestream = np.array([rho, rho*u, rho*v, e])
+            sol_data = np.zeros((128, 256, 4))
+            sol_data[:, :] = freestream
+            for i in range(len(self.loc_to_idx)):
+                idx1, idx2 = self.loc_to_idx[i]
+                sol_data[idx1, idx2] = data[i][1]
+
+            # Update running total of previous states
+            if self.perform_online_dmdc:
+                self.X = np.vstack((self.X[1:], np.expand_dims(sol_data, axis=0)))
+
+            # Initialize values
+            t = intg.tcurr
+            self.t_old = t
+            pred_error = 0.0
+            self.iteration = self.iteration+1
+            print("\nIteration: ", self.iteration, "\n")
+
+            if self.set_omega == 0:
+                omega = 0.0
+            elif self.perform_offline_dmdc:
+                x0 = self.U_hat_t @ sol_data.flatten()
+                omega = self._find_mpc_input(self.A, self.B, x0)
+            elif self.perform_online_dmdc:
+                # If we have seen enough input, update, A, B and U_hat_t
+                if self.iteration % self.dmdc_recompute_duration == 0 and np.linalg.norm(self.X[0]) > 0.0:
+                    self._find_dmdc_dynamics()
+
+                # Transform the current state and goal state based on the tranform corresponding to A
+                x0 = self.U_hat_t @ sol_data.flatten()
+                self.goal_state = self.U_hat_t @ self.raw_goal_state
+
+                # Find the optimal control input
+                omega = self._find_mpc_input(self.A, self.B, x0)
+                self.u = np.concatenate((self.u[1:], np.expand_dims(np.array([omega]), axis=0)))
+            else:
+                # omega = random.uniform(-0.01, 0.01)
+
+                # To generate training data
+                # Have no inputs for periods, otherwise sinusoidal
+                if t % 1000 > 900:
+                   omega = 0.0
+                else:
+                   freq = 2*np.pi * (t/1000)/500.0
+                   omega = 0.3*np.sin(freq*t)
+
+                # Proportional control
+                # location = 88 # re50
+                # gain = 0.4 # re50
+                # rho = sol_data[64, location, 0]
+                # rho_v = sol_data[64, location, 2]
+                # omega = gain*rho_v/rho
+
+
+            # Save data if desired
+            if self.save_data == 1:
+                # Save to h5 file
+                file_num += 1
+                filename = self.save_dir + '/sol_data_' + str(file_num).zfill(4) + '.h5'
+                f = h5py.File(filename, 'w')
+                f['sol_data'] = sol_data
+                f['control_input'] = omega
+                if self.perform_offline_dmdc or self.perform_online_dmdc:
+                    f['cost'] = np.linalg.norm(self.goal_state - x0)
+                f.close()
+        else:
+            omega = None
+
+        # Broadcast omega to all of the MPI ranks
+        intg.system.omega = float(comm.bcast(omega, root=root))
